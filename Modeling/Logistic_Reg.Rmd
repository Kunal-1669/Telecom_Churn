---
title: "Logistic Regression"
author: "Sunisha Harish"
date: "2022-12-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ezids)
library(caTools)
library(caret)
```

## Testing  Git Hub Commits

## Logit Model with Over Sampling (SMOTE)

```{r data,results=T}
train_data=data.frame(read.csv("C:\\GitHub Repositories\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_data=data.frame(read.csv("C:\\GitHub Repositories\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
train_data$class=as.factor(train_data$class)
test_data$class=as.factor(test_data$class)
str(train_data)
str(test_data)
```

## Model building

```{r logit,results=T}
model=glm(class ~ ., train_data, family = "binomial")
pred=predict(model,newdata=test_data)
#pred[pred >= 0.5]=1         
#pred[pred < 0.5 ]=0
#pred=as.factor(pred)
summary(model)
```

## Confusion matrix

```{r logit,results=T}


confusion_matrix=table(test_data$class,pred>=0.5)
xkabledply(confusion_matrix)
TP=confusion_matrix[2,2]
FP=confusion_matrix[2,1]
TN=confusion_matrix[1,1]
FN=confusion_matrix[1,2]
Accuracy=(TP+TN)/(TP+FP+TN+FN)
Accuracy
Precision = TP/(TP + FP)
Precision
Recall = TP/(TP + FN)
Recall

```

```{r logit,results=T}
confusion_mtx = confusionMatrix(pred,test_data$class,mode = "everything")
print(confusion_mtx)
```


## Logit Model with under sampling

```{r data,results=T}
train_data=data.frame(read.csv("C:\\GitHub Repositories\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
test_data=data.frame(read.csv("C:\\GitHub Repositories\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))
train_data$Churn=as.factor(train_data$Churn)
test_data$Churn=as.factor(test_data$Churn)
str(train_data)
str(test_data)
```

## Model building

```{r logit,results=T}
model=glm(Churn ~ ., train_data, family = "binomial")
pred=predict(model,newdata=test_data,type="response")
#pred[pred >= 0.5]=1         
#pred[pred < 0.5 ]=0
#pred=as.factor(pred)
summary(model)
```

```{r logit,results=T}


confusion_matrix=table(test_data$Churn,pred>=0.5)
xkabledply(confusion_matrix)
TP=confusion_matrix[2,2]
FP=confusion_matrix[2,1]
TN=confusion_matrix[1,1]
FN=confusion_matrix[1,2]
Accuracy=(TP+TN)/(TP+FP+TN+FN)
Accuracy
Precision = TP/(TP + FP)
Precision
Recall = TP/(TP + FN)
Recall

```

## Confusion matrix

```{r logit,results=T}
confusion_mtx = confusionMatrix(pred,test_data$Churn,mode = "everything")
print(confusion_mtx)
```





