---
# This is the YAML header/metadata for the document
title: "Customer Churn Analysis code & Technical Analysis"
author: "Pranav Chandaliya"

output:
  html_document:
    code_folding: hide
    number_sections: true
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
#library(ezids)

```


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r,results="show"}
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
ncol(train_smote)
nrow(train_smote)

test <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv"))
ncol(test)
nrow(test)

str(train_smote)
```
```{r,results="show"}
# Loading package
library(caTools)
library(randomForest)

x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class

x_test <- subset(test, select = -c(Churn))
y_test <-test$Churn

y_train<-factor(y_train)
y_test<-factor(y_test)

# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
                             y = y_train,
                             ntree = 500)
  

  
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
  
# Confusion Matrix
confusion_mtx = table(y_test, y_pred)
confusion_mtx
  
# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)




```
```{r,results="show"}

library(pROC)
rf_prediction <- predict(classifier_RF, x_test,type = "prob")

ROC_rf <- roc(y_test, rf_prediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test

```

```{r,results="show"}
ROC_rf_auc <- auc(ROC_rf)

rf_prediction <- predict(classifier_RF, x_train,type = "prob")

ROC_rf <- roc(y_train, rf_prediction[,2])
ROC_rf
ROC_rf_auc_train <- auc(ROC_rf)
ROC_rf_auc_train
```

```{r,results="show"}
train_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
ncol(train_under)
nrow(train_under)

test_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))
ncol(test_under)
nrow(test_under)

str(test_under)
```


```{r,results="show"}
# Loading package
library(caTools)
library(randomForest)
library(caret)



x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn

x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn

y_train<-factor(y_train)
y_test<-factor(y_test)

# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
                             y = y_train,
                             ntree = 500)
  

  
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
  
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
  
# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)




```
```{r,results="show"}
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))

test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))


x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class

table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)


y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)

# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
                             y = y_train,
                             ntree = 500)
  

  
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
  
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"             
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)



#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"             
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)

#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
  
# Plotting model
plot(classifier_RF)
  
# Importance plot
importance(classifier_RF)
  
# Variable importance plot
varImpPlot(classifier_RF)



```
```{r,results="show"}
#library("InformationValue")
y_pred = predict(classifier_RF, newdata = x_test,type="prob")
y_pred = y_pred[,2]
#optimal <- optimalCutoff(y_test, y_pred)[1]


```
```{r,results="show"}


imp_feats<-importance(classifier_RF)
ggplot(imp_feats,aes(x=Occupation)) + geom_bar(fill = "aquamarine3") + ggtitle("Frequency distribution of occupation")+ theme_classic()


```

```{r,results="show"}

rf_uprediction <- predict(classifier_RF, x_test,type = "prob")

ROC_rf <- roc(y_test, rf_uprediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test

confusion_mtx = confusionMatrix(y_prob,y_utest,mode = "everything")




```


```{r,results="show"}


library(ROCR)
prediction(rf_uprediction[,2], y_utest
performance(measure = "tpr", x.measure = "fpr") -> result

plotdata <- data.frame(x = result@x.values[[1]],
                       y = result@y.values[[1]], 
                       p = result@alpha.values[[1]])

p <- ggplot(data = plotdata) +
  geom_path(aes(x = x, y = y)) + 
  xlab(result@x.name) +
  ylab(result@y.name) +
  theme_bw()

dist_vec <- plotdata$x^2 + (1 - plotdata$y)^2
opt_pos <- which.min(dist_vec)

p + 
  geom_point(data = plotdata[opt_pos, ], 
             aes(x = x, y = y), col = "red") +
  annotate("text", 
           x = plotdata[opt_pos, ]$x + 0.1,
           y = plotdata[opt_pos, ]$y,
           label = paste("p =", round(plotdata[opt_pos, ]$p, 3)))
```

```{r,results="show"}

### Trying different threshold values to improve recall/sensitivity

thresh <- c(0.3, 0.35 ,0.4 ,0.45, 0.5, 0.55, 0.60,0.65)

table(y_test)
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob =y_pred[,2]

y_test=as.numeric(y_test)
y_test[y_test == 1] <-  "No"             
y_test[y_test == 2] <-   "Yes"
  
y_test <- as.factor(y_test)


for (x in thresh) {
  print("Threshold")
  print(x)
  y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
  y_prob =y_pred[,2]

  y_prob[y_prob >= x] <-  "Yes"             
  y_prob[y_prob < x] <-   "No"
  
  
  
  
  y_prob <- as.factor(y_prob)
  confusion_mtx = confusionMatrix(y_prob,y_test,mode = "everything",positive="Yes")
  print(confusion_mtx)
  

  
  
}




```
``````{r,results="show"}
thresh <- c(0.3, 0.35,0.40,0.45)
Accuracy <- c(0.67,0.72,0.76,0.77)
Recall <- c(0.85,0.75,0.66,0.58)

metrics <- data.frame(thresh, Accuracy,Recall)

library(plotly)
t <- list(
  family = "sans serif",
  size = 14,
  color = toRGB("grey50"))


fig <- plot_ly(metrics, x = ~Accuracy, y = ~Recall, text = ~thresh)
fig <- fig %>% add_markers()
fig <- fig %>% add_text(textfont = t, textposition = "top right")


fig


```

```{r,results="show"}
# Encoding the target feature as factor


# Splitting the dataset into
# the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)

training_set = data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
test_set = data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))


training_set$Churn = factor(training_set$Churn,
						levels = c(0, 1))

test_set$Churn = factor(test_set$Churn,
						levels = c(0, 1))

# Fitting Decision Tree Classification
# to the Training set
# install.packages('rpart')
library(tree)
classifier = tree(formula = Churn ~ .,
				data = training_set)

# Predicting the Test set results
y_pred = predict(classifier,
				newdata = test_set,
				type = 'class')

# Making the Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,test_set$Churn,mode = "everything")
```

```{r,results="show"}

i_scores <- varImp(classifier_RF, conditional=TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart. 
i_scores <- i_scores %>% tibble::rownames_to_column("var") 
i_scores$var<- i_scores$var %>% as.factor()

plot_ly(
  data = i_scores,
  x = ~var,
  y = ~Overall,
  type = "bar"
) %>% 
layout(xaxis = list(categoryorder = "total descending"))

```

```{r,results="show"}


y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
print(" 0.80")
length(y_prob[y_prob >= 0.80])
##1872
print(" 0.60")
length(y_prob[y_prob >= 0.60]) - 1872
##864


```