<<<<<<< Updated upstream
train$Churn = factor(train$class)
data <- read.csv(file = 'prepro_telcom_data.csv')
str(data)
head(data)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
library(naivebayes)
library(dplyr)
library(ggplot2)
library(psych)
x = train[,-9]
y = train$Churn
x = train[,-9]
y = train$Churn
train$Churn = factor(train$class)
model <- naive_bayes(Churn ~ ., data = train, usekernel = T)
library(pROC)
prediction <- predict(model, test, type="prob")
roc_object <- roc( test$Churn, prediction[,2])
auc( roc_object )
prediction_train <- predict(model, train, type="prob")
roc_object_train <- roc( train$Churn, prediction_train[,2])
auc( roc_object_train )
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
train$Churn = factor(train$class)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
train$Churn = factor(train$class)
x = train[,-9]
y = train$Churn
train$Churn = factor(train$class)
data <- read.csv(file = 'prepro_telcom_data.csv')
str(data)
head(data)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
library(naivebayes)
library(dplyr)
library(ggplot2)
library(psych)
library(pROC)
prediction <- predict(model, test, type="prob")
roc_object <- roc( test$Churn, prediction[,2])
auc( roc_object )
prediction_train <- predict(model, train, type="prob")
roc_object_train <- roc( train$Churn, prediction_train[,2])
data <- read.csv(file = 'prepro_telcom_data.csv')
str(data)
head(data)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
library(naivebayes)
library(dplyr)
library(ggplot2)
library(psych)
x = train[,-9]
y = train$Churn
train$Churn = factor(train$class)
model <- naive_bayes(Churn ~ ., data = train, usekernel = T)
library(pROC)
prediction <- predict(model, test, type="prob")
roc_object <- roc( test$Churn, prediction[,2])
auc( roc_object )
prediction_train <- predict(model, train, type="prob")
roc_object_train <- roc( train$Churn, prediction_train[,2])
auc( roc_object_train )
data <- read.csv(file = 'prepro_telcom_data.csv')
str(data)
head(data)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
library(naivebayes)
library(dplyr)
library(ggplot2)
library(psych)
x = train[,-9]
y = train$Churn
train$Churn = factor(train$class)
#Use 70% of dataset as training set and remaining 30% as testing set
sample <- sample(c(TRUE, FALSE), nrow(data), replace=TRUE, prob=c(0.7,0.3))
#train  <- data[sample, ]
#test   <- data[!sample, ]
train <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv')
test <- read.csv(file = 'C:\\Users\\Vaishnavi\\OneDrive\\Desktop\\into to data science project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv')
#view dimensions of training set
dim(train)
#view dimensions of test set
dim(test)
library(naivebayes)
library(dplyr)
library(ggplot2)
library(psych)
x = train[,-9]
y = train$Churn
train$Churn = factor(train$class)
model <- naive_bayes(Churn ~ ., data = train, usekernel = T)
library(pROC)
prediction <- predict(model, test, type="prob")
roc_object <- roc( test$Churn, prediction[,2])
auc( roc_object )
prediction_train <- predict(model, train, type="prob")
roc_object_train <- roc( train$Churn, prediction_train[,2])
auc( roc_object_train )
=======
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#library(ggplot2)
library(caret)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#library(ggplot2)
loadPkg("caret")
install.packages()loadPkg("caret")
loadPkg("caret")
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
library(rlang)
sessionInfo()
remove.packages(rlang)
remove.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
library(tidyverse)
install.packages("rlang")
install.packages("rlang")
library(tidyverse)
library(ggplot2)
install.packages("rlang")
install.packages("rlang")
update.packages("rlang")
library(ggplot2)
update.packages()
library(ggplot2)
library(tidyverse)
sessionInfo()
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
install.packages(c("cli", "jsonlite", "plyr", "purrr", "tidyr", "vctrs"))
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
#library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
ncol(train_smote)
nrow(train_smote)
test <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv"))
ncol(test)
nrow(test)
str(train_smote)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
x_test <- subset(test, select = -c(Churn))
y_test <-test$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
# Confusion Matrix
confusion_mtx = table(y_test, y_pred)
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
library(pROC)
rf_prediction <- predict(classifier_RF, x_test,type = "prob")
ROC_rf <- roc(y_test, rf_prediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test
ROC_rf_auc <- auc(ROC_rf)
rf_prediction <- predict(classifier_RF, x_train,type = "prob")
ROC_rf <- roc(y_train, rf_prediction[,2])
ROC_rf
ROC_rf_auc_train <- auc(ROC_rf)
ROC_rf_auc_train
train_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
ncol(train_under)
nrow(train_under)
test_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))
ncol(test_under)
nrow(test_under)
str(test_under)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#library(ggplot2)
loadPkg("caret")
library(caret)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_test, y_pred,mode = "everything")
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_test, y_pred[,2],mode = "everything")
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,mode ="prob")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_test, y_pred[,2],mode = "everything")
str(y_pred)
str
y_pred
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_test, y_pred[,2],mode = "everything")
y_test
str(y_test)
str(y_pred[,2])
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_test, as.factor(y_pred[,2]),mode = "everything")
confusion_mtx = confusionMatrix(y_pred, as.factor(y_pred[,2]),mode = "everything")
confusion_mtx = confusionMatrix(y_pred, y_test,mode = "everything")
confusion_mtx = confusionMatrix(y_pred[,2], y_test,mode = "everything")
confusion_mtx = confusionMatrix(as.factor(y_pred[,2]), as.factor(y_test),mode = "everything")
str(y_pred[,2])
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
y_pred
confusion_mtx = confusionMatrix(as.factor(y_pred[,2]), as.factor(y_test),mode = "everything")
confusion_mtx = confusionMatrix(as.factor(y_pred), as.factor(y_test),mode = "everything")
str(y_pred)
str(y_test)
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
confusionMatrix(y_pred,y_test,mode = "everything")
nrow(y_test)
length(y_test)
nrow(y_pred)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-train_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
train_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
ncol(train_under)
nrow(train_under)
test_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))
ncol(test_under)
nrow(test_under)
str(test_under)
length(y_test)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
rf_prediction <- predict(classifier_RF, x_test,type = "prob")
ROC_rf <- roc(y_test, rf_prediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 20)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
rf_prediction <- predict(classifier_RF, x_test,type = "prob")
ROC_rf <- roc(y_test, rf_prediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 100)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_utest <- subset(test_under, select = -c(Churn))
y_utest <-test_under$Churn
y_utrain<-factor(y_train)
y_utest<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_uRF = randomForest(x = x_utrain,
y = y_utrain,
ntree = 100)
# Loading package
library(caTools)
library(randomForest)
x_utrain<-subset(train_under, select = -c(Churn))
y_utrain<-train_under$Churn
x_utest <- subset(test_under, select = -c(Churn))
y_utest <-test_under$Churn
y_utrain<-factor(y_train)
y_utest<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_uRF = randomForest(x = x_utrain,
y = y_utrain,
ntree = 100)
# Predicting the Test set results
y_pred_u = predict(classifier_uRF, newdata = x_utest,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred_u,y_utest,mode = "everything")
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
rf_uprediction <- predict(classifier_uRF, x_utest,type = "prob")
ROC_rf <- roc(y_utest, rf_uprediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test
# Loading package
library(caTools)
library(randomForest)
x_utrain<-subset(train_under, select = -c(Churn))
y_utrain<-train_under$Churn
x_utest <- subset(test_under, select = -c(Churn))
y_utest <-test_under$Churn
y_utrain<-factor(y_train)
y_utest<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_uRF = randomForest(x = x_utrain,
y = y_utrain,
ntree = 500)
# Predicting the Test set results
y_pred_u = predict(classifier_uRF, newdata = x_utest,type ="response")
library(caret  )
#loadPkg("caret")
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred_u,y_utest,mode = "everything")
confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
rf_uprediction <- predict(classifier_uRF, x_utest,type = "prob")
ROC_rf <- roc(y_utest, rf_uprediction[,2])
ROC_rf
ROC_rf_auc_test <- auc(ROC_rf)
ROC_rf_auc_test
library(ROCR)
install.packages(ROCR)
install.packages("ROCR")
library(ROCR)
prediction(rf_uprediction[,2], y_utest) %>%
performance(measure = "tpr", x.measure = "fpr") -> result
library(ROCR)
prediction(rf_uprediction[,2], y_utest)
performance(measure = "tpr", x.measure = "fpr") -> result
install.packages("cutpointr")
thresh <- c(0.3, 0.35 ,0.4 ,0.45, 0.5, 0.55, 0.60,0.65)
y_pred = predict(classifier_uRF, newdata = x_utest,type ="prob")
y_prob =y_pred[,2]
for (x in thresh) {
print("Threshold")
print(x)
y_prob[y_prob >= x] <-   1
y_prob[y_prob < x] <-   0
confusion_mtx = confusionMatrix(y_prob,y_utest,mode = "everything")
confusion_mtx
}
thresh <- c(0.3, 0.35 ,0.4 ,0.45, 0.5, 0.55, 0.60,0.65)
y_pred = predict(classifier_uRF, newdata = x_utest,type ="prob")
y_prob =y_pred[,2]
for (x in thresh) {
print("Threshold")
print(x)
y_prob[y_prob >= x] <-   1
y_prob[y_prob < x] <-   0
y_prob <- factor(y_prob)
confusion_mtx = confusionMatrix(y_prob,y_utest,mode = "everything")
confusion_mtx
}
>>>>>>> Stashed changes
