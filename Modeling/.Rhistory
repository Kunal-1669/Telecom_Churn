table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 150)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything",postive="1")
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 150)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
install.packages("InformationValue ")
library("InformationValue")
#library("InformationValue")
y_pred = predict(classifier_RF, newdata = x_test,type="prob")
y_pred = y_pred[,2]
optimal <- optimalCutoff(y_test, y_pred)[1]
install.packages("InformationValue")
devtools::install_github("InformationValue")  # For latest dev version.
update.packages(‘cli’)
update.packages(cli)
varImpPlot(classifier_RF)
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 150)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
imp_feats<-importance(classifier_RF)
imp_feats
type(imp_feats)
describe(imp_feats)
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course.
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
#library(ezids)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
ncol(train_smote)
nrow(train_smote)
test <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test.csv"))
ncol(test)
nrow(test)
str(train_smote)
# Loading package
library(caTools)
library(randomForest)
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
x_test <- subset(test, select = -c(Churn))
y_test <-test$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 500)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
# Loading package
library(caTools)
library(randomForest)
library(caret)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 150)
confusion_mtx
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 500)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
### Trying different threshold values to improve recall/sensitivity
thresh <- c(0.3, 0.35 ,0.4 ,0.45, 0.5, 0.55, 0.60,0.65)
table(y_test)
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob =y_pred[,2]
y_test=as.numeric(y_test)
y_test[y_test == 1] <-  "No"
y_test[y_test == 2] <-   "Yes"
y_test <- as.factor(y_test)
for (x in thresh) {
print("Threshold")
print(x)
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob =y_pred[,2]
y_prob[y_prob >= x] <-  "Yes"
y_prob[y_prob < x] <-   "No"
y_prob <- as.factor(y_prob)
confusion_mtx = confusionMatrix(y_prob,y_test,mode = "everything",positive="Yes")
print(confusion_mtx)
}
thresh <- c(0.3, 0.35,0.40,0.45)
Accuracy <- c(0.67,0.72,0.76,0.77)
Recall <- c(0.85,0.75,0.66,0.58)
metrics <- data.frame(thresh, Accuracy,Recall)
library(plotly)
t <- list(
family = "sans serif",
size = 14,
color = toRGB("grey50"))
fig <- plot_ly(metrics, x = ~Accuracy, y = ~Recall, text = ~thresh)
fig <- fig %>% add_markers()
fig <- fig %>% add_text(textfont = t, textposition = "top right")
fig <- fig %>% layout(xaxis = list(range = c(1.6, 3.2)),
showlegend = FALSE)
fig
thresh <- c(0.3, 0.35,0.40,0.45)
Accuracy <- c(0.67,0.72,0.76,0.77)
Recall <- c(0.85,0.75,0.66,0.58)
metrics <- data.frame(thresh, Accuracy,Recall)
library(plotly)
t <- list(
family = "sans serif",
size = 14,
color = toRGB("grey50"))
fig <- plot_ly(metrics, x = ~Accuracy, y = ~Recall, text = ~thresh)
fig <- fig %>% add_markers()
fig <- fig %>% add_text(textfont = t, textposition = "top right")
fig
summary(classifier_RF)
summary()
summary(classifier_RF)
i_scores <- varImp(classifier_RF, conditional=TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart.
i_scores <- i_scores %>% tibble::rownames_to_column("var")
i_scores$var<- i_scores$var %>% as.factor()
i_scores
i_scores <- varImp(classifier_RF, conditional=TRUE)
#Gathering rownames in 'var'  and converting it to the factor
#to provide 'fill' parameter for the bar chart.
i_scores <- i_scores %>% tibble::rownames_to_column("var")
i_scores$var<- i_scores$var %>% as.factor()
plot_ly(
data = i_scores,
x = ~var,
y = ~Overall,
type = "bar"
) %>%
layout(xaxis = list(categoryorder = "total descending"))
devtools::install_github('ModelOriented/treeshap')
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_pred
y_prob=y_pred[,2]
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
nrow(y_pred[y_prob >= 0.90])
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
nrow(y_prob[y_prob >= 0.90])
length(y_prob[y_prob >= 0.90])
print(" 0.60")
length(y_prob[y_prob >= 0.60]) - 1872
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
print(" 0.80")
length(y_prob[y_prob >= 0.80])
##1872
print(" 0.60")
length(y_prob[y_prob >= 0.60]) - 1872
##864
print(" 0.40")
length(y_prob[y_prob >= 0.60]) - 1872 - 864
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
print(" 0.80")
length(y_prob[y_prob >= 0.80])
##1872
print(" 0.60")
length(y_prob[y_prob >= 0.60]) - 1872
##864
print(" 0.35")
length(y_prob[y_prob >= 0.60]) - 1872 - 864
y_pred = predict(classifier_RF, newdata = x_test,type ="prob")
y_prob=y_pred[,2]
print(" 0.80")
length(y_prob[y_prob >= 0.80])
##1872
print(" 0.60")
length(y_prob[y_prob >= 0.60]) - 1872
##864
length(y_prob[y_prob >= 0.80])
length(y_prob[y_prob >= 0.60]) - 1872
train_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_under.csv"))
ncol(train_under)
nrow(train_under)
test_under <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_under.csv"))
ncol(test_under)
nrow(test_under)
str(test_under)
# Loading package
library(caTools)
library(randomForest)
library(caret)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 50)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
# Loading package
library(caTools)
library(randomForest)
library(caret)
x_train<-subset(train_under, select = -c(Churn))
y_train<-train_under$Churn
x_test <- subset(test_under, select = -c(Churn))
y_test <-test_under$Churn
y_train<-factor(y_train)
y_test<-factor(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 500)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
# Loading package
## SMOTE
library(caTools)
library(randomForest)
library(caret)
train_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\train_smote.csv"))
test_smote <- data.frame(read.csv("D:\\ID_Project\\T9-Outlier-22FA\\Data Preprocessing\\test_smote.csv"))
x_train<-subset(train_smote, select = -c(class))
y_train<-train_smote$class
table(y_train)
x_test <- subset(test_smote, select = -c(class))
y_test <-test_smote$class
table(y_test)
y_train<-factor(y_train,levels = c(0, 1))
y_test<-factor(y_test,levels = c(0, 1))
table(y_train)
table(y_test)
# Fitting Random Forest to the train dataset
set.seed(120)  # Setting seed
classifier_RF = randomForest(x = x_train,
y = y_train,
ntree = 500)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = x_test)
#y_test=as.numeric(y_test)
#y_test[y_test == 0] <-  "No"
#y_test[y_test == 1] <-   "Yes"
#y_test = factor(y_test)
#table(y_test)
#y_pred=as.numeric(y_pred)
#y_pred[y_pred == 0] <-  "No"
#y_pred[y_pred == 1] <-   "Yes"
#y_pred = factor(y_pred)
#table(y_pred)
#y
# Confusion Matrix
confusion_mtx = confusionMatrix(y_pred,y_test,mode = "everything")
print(confusion_mtx)
#confusion_mtx = table(y_test, y_pred)
#confusion_mtx
# Plotting model
plot(classifier_RF)
# Importance plot
importance(classifier_RF)
# Variable importance plot
varImpPlot(classifier_RF)
